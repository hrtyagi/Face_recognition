{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Face recognition using k-Nearest Neighbours Algorithm, Haarcascades Classifier & openCV for python**\n",
    "* Face recognition is all about those meaningful features from an image ,putting them into a useful representation and performing some classifications on them.\n",
    "* This is a very basic form of face recognition,because nowadays we have more improved and accurate algo like pca,hmm and deep learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps\n",
    "* First we'll prepare a good database of faces with multiple images for each individual.\n",
    "* Then import the faces in the database images and use them to train the face recognizer model,which is KNN in our case.\n",
    "* Test the face recognizer to recognize faces it was trained for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenCV-Read a video stream from webcam frame by frame\n",
    "Opencv is a library useful while we want to work with images. It is shipped as cv2.Basically weâ€™ll be using this library to read and write images and to input a video stream also.When opencv reads an image,it is an RGB image.Therefore,each image has 3 channels.So,when we read an image using opencv,opencv by default reads these channels as BGR.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "#Init Camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret,frame = cap.read()\n",
    "        gray_frame = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    if ret==False:\n",
    "        continue \n",
    "\n",
    "        cv2.imshow(\"Video Frame\",frame)\n",
    "        cv2.imshow(\"Gray Frame\" ,gray_frame)\n",
    "\n",
    "    key_pressed = cv2.waitKey(1) & 0xFF\n",
    "    if key_pressed == ord('q'):\n",
    "        break\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Detect Faces and show box over the detected faces using Haarcascade Classifier***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Haar Cascades \n",
    "It is a pretained model used to detect faces.This is basically a machine learning based approach where a cascade function is trained from a lot of images both positive and negative. Based on the training it is then used to detect the objects in the other images.Haar Cascades uses the Ada-boost learning algorithm which selects a small number of important features from a large set to give an efficient result of classifiers then use cascading techniques to detect the face in an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "#Init Camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Face Detection\n",
    "face_cascade = cv2.CascadeClassifier(\"haarcascade_frontalface_alt.xml\")\n",
    "\n",
    "while True:\n",
    "    ret,frame = cap.read()\n",
    "    gray_frame=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    if ret==False:\n",
    "        continue\n",
    "    faces = face_cascade.detectMultiScale(frame,1.3,5)\n",
    "    print(faces)\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "        cv2.rectangle(gray_frame,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "\n",
    "    cv2.imshow(\"Video Frame\",frame)\n",
    "    cv2.imshow(\"Gray Frame\" ,gray_frame)\n",
    "\n",
    "    key_pressed = cv2.waitKey(1) & 0xFF\n",
    "    if key_pressed == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate Training data using webcam**\n",
    "* Read and show video stream,capture images\n",
    "* Detect faces and show bounding box \n",
    "* Flatten the largest face image(gray scale image) and save in a numpy array(storing every 10th frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#Init Camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Face Detection\n",
    "face_cascade = cv2.CascadeClassifier(\"haarcascade_frontalface_alt.xml\")\n",
    "\n",
    "skip = 0\n",
    "face_data = []\n",
    "dataset_path = './image_data/'\n",
    "file_name = input(\"Enter the name of the person : \")\n",
    "while True:\n",
    "    ret,frame = cap.read()\n",
    "\n",
    "    if ret==False:\n",
    "        continue\n",
    "\n",
    "\n",
    "    gray_frame = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "    faces = face_cascade.detectMultiScale(frame,1.3,5)\n",
    "    if len(faces)==0:\n",
    "        continue\n",
    "\n",
    "    faces = sorted(faces,key=lambda f:f[2]*f[3])\n",
    "\n",
    "    # Pick the last face (because it is the largest face acc to area(f[2]*f[3]))\n",
    "    for face in faces[-1:]:\n",
    "        x,y,w,h = face\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "\n",
    "\n",
    "\n",
    "    #Extract (Crop out the required face) : Region of Interest\n",
    "    offset = 10\n",
    "    face_section = frame[y-offset:y+h+offset,x-offset:x+w+offset]\n",
    "    face_section = cv2.resize(face_section,(100,100))\n",
    "\n",
    "    skip += 1\n",
    "    if skip%10==0:\n",
    "        face_data.append(face_section)\n",
    "        print(len(face_data))\n",
    "\n",
    "\n",
    "    cv2.imshow(\"Frame\",frame)\n",
    "    cv2.imshow(\"Face Section\",face_section)\n",
    "\n",
    "    key_pressed = cv2.waitKey(1) & 0xFF\n",
    "    if key_pressed == ord('q'):\n",
    "        break\n",
    "\n",
    "# Convert our face list array into a numpy array\n",
    "face_data = np.asarray(face_data)\n",
    "face_data = face_data.reshape((face_data.shape[0],-1))\n",
    "print(face_data.shape)\n",
    "\n",
    "# Save this data into file system\n",
    "np.save(dataset_path+file_name+'.npy',face_data)\n",
    "print(\"Data Successfully save at \"+dataset_path+file_name+'.npy')\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Recognition using KNN\n",
    "We are using KNN to work upon the dataset,that we have generated using webcam images. So the first step was reading video stream and extracting faces out of it.These faces will be used for testing purposes for which we want to predict the label.We have the test data, we will also load training data.Goal of the algorithm would be that when a new image is given, we want to extract the face and we want to see with whose face it resembles the most. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np \n",
    "import os \n",
    "\n",
    "def distance(v1, v2):\n",
    "    # Eucledian \n",
    "    return np.sqrt(((v1-v2)**2).sum())\n",
    "\n",
    "def knn(train, test, k=5):\n",
    "    dist = []\n",
    "\n",
    "    for i in range(train.shape[0]):\n",
    "        # Get the vector and label\n",
    "        ix = train[i, :-1]\n",
    "        iy = train[i, -1]\n",
    "        # Compute the distance from test point\n",
    "        d = distance(test, ix)\n",
    "        dist.append([d, iy])\n",
    "    # Sort based on distance and get top k\n",
    "    dk = sorted(dist, key=lambda x: x[0])[:k]\n",
    "    # Retrieve only the labels\n",
    "    labels = np.array(dk)[:, -1]\n",
    "\n",
    "    # Get frequencies of each label\n",
    "    output = np.unique(labels, return_counts=True)\n",
    "    # Find max frequency and corresponding label\n",
    "    index = np.argmax(output[1])\n",
    "    return output[0][index]\n",
    "\n",
    "\n",
    "#Init Camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Face Detection\n",
    "face_cascade = cv2.CascadeClassifier(\"haarcascade_frontalface_alt.xml\")\n",
    "\n",
    "skip = 0\n",
    "dataset_path = './image_data/'\n",
    "\n",
    "face_data = [] \n",
    "labels = []\n",
    "\n",
    "class_id = 0 # Labels for the given file\n",
    "names = {} #Mapping btw id - name\n",
    "\n",
    "\n",
    "# Data Preparation\n",
    "for fx in os.listdir(dataset_path):\n",
    "    if fx.endswith('.npy'):\n",
    "       #Create a mapping btw class_id and name\n",
    "        names[class_id] = fx[:-4]\n",
    "        print(\"Loaded \"+fx)\n",
    "        data_item = np.load(dataset_path+fx)\n",
    "        face_data.append(data_item)\n",
    "\n",
    "        #Create Labels for the class\n",
    "        target = class_id*np.ones((data_item.shape[0],))\n",
    "        class_id += 1\n",
    "        labels.append(target)\n",
    "\n",
    "face_dataset = np.concatenate(face_data,axis=0)\n",
    "face_labels = np.concatenate(labels,axis=0).reshape((-1,1))\n",
    "\n",
    "print(face_dataset.shape)\n",
    "print(face_labels.shape)\n",
    "\n",
    "trainset = np.concatenate((face_dataset,face_labels),axis=1)\n",
    "print(trainset.shape)\n",
    "\n",
    "# Testing \n",
    "\n",
    "while True:\n",
    "    ret,frame = cap.read()\n",
    "    if ret == False:\n",
    "        continue\n",
    "\n",
    "    faces = face_cascade.detectMultiScale(frame,1.3,5)\n",
    "    if(len(faces)==0):\n",
    "        continue\n",
    "\n",
    "    for face in faces:\n",
    "        x,y,w,h = face\n",
    "\n",
    "        #Get the face ROI\n",
    "        offset = 10\n",
    "        face_section = frame[y-offset:y+h+offset,x-offset:x+w+offset]\n",
    "        face_section = cv2.resize(face_section,(100,100))\n",
    "\n",
    "        #Predicted Label (out)\n",
    "        out = knn(trainset,face_section.flatten())\n",
    "\n",
    "        #Display on the screen the name and rectangle around it\n",
    "        pred_name = names[int(out)]\n",
    "        cv2.putText(frame,pred_name,(x,y-10),cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,255),2,cv2.LINE_AA)\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "\n",
    "    cv2.imshow(\"Faces\",frame)\n",
    "\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key==ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
